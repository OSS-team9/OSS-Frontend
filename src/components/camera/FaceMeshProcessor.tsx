"use client";

import { useState, useEffect, useRef } from "react";
import { FaceLandmarker, FilesetResolver } from "@mediapipe/tasks-vision";
import * as ort from "onnxruntime-web"; // ONNX Runtime ì¶”ê°€
import Card from "@/components/common/BorderCard";
import LoadingSpinner from "@/components/common/LoadingSpinner";
import { useShareAndDownload } from "@/hooks/useShareAndDownload";
import { getTodayDateString } from "@/utils/dateUtils";

// â­ï¸ [ë©”ëª¨ë¦¬ ìµœì í™”] ì „ì—­ ì„¤ì •
ort.env.wasm.numThreads = 1;
ort.env.wasm.simd = false;
ort.env.wasm.proxy = false;

// ==================================================
// ê°ì • ë¼ë²¨
// ==================================================
const EMOTIONS = [
  "sadness",
  "joy",
  "anger",
  "anxiety",
  "panic",
  "hurt",
  "neutral",
];

// ==================================================
// ì•„ì´ì½˜ ë°°ì¹˜ ì„¤ì • (User Original)
// ==================================================
const ICON_PLACEMENTS = [
  {
    id: "top",
    landmarkIndex: 10,
    width: 432,
    height: 432,
    offsetX: -216,
    offsetY: -540,
  },
  {
    id: "left",
    landmarkIndex: 127,
    width: 360,
    height: 360,
    offsetX: -432,
    offsetY: -180,
  },
  {
    id: "right",
    landmarkIndex: 356,
    width: 324,
    height: 324,
    offsetX: 108,
    offsetY: -162,
  },
];

// ==================================================
// softmax
// ==================================================
function softmax(arr: number[]) {
  const m = Math.max(...arr);
  const exps = arr.map((v) => Math.exp(v - m));
  const sum = exps.reduce((a, b) => a + b, 0);
  return exps.map((v) => v / sum);
}

// ==================================================
// ì–¼êµ´ Bounding Box ê³„ì‚° (ì „ì²´ ì´ë¯¸ì§€ ê¸°ì¤€)
// ==================================================
function computeBBox(lm: any[]) {
  let minX = 1,
    minY = 1,
    maxX = 0,
    maxY = 0;
  for (const p of lm) {
    minX = Math.min(minX, p.x);
    minY = Math.min(minY, p.y);
    maxX = Math.max(maxX, p.x);
    maxY = Math.max(maxY, p.y);
  }
  const w = maxX - minX;
  const h = maxY - minY;
  const pad = 0.1;
  return {
    x: Math.max(0, minX - w * pad),
    y: Math.max(0, minY - h * pad),
    w: Math.min(1, w * (1 + pad * 2)),
    h: Math.min(1, h * (1 + pad * 2)),
  };
}

// ==================================================
// crop ê¸°ì¤€ landmark â†’ 1434 ë²¡í„°
// ==================================================
function landmarksToVec1434_CropNorm(
  lm: any[],
  bbox: { x: number; y: number; w: number; h: number }
): Float32Array {
  const out = new Float32Array(1434);
  for (let i = 0; i < 478; i++) {
    const nx = (lm[i].x - bbox.x) / bbox.w;
    const ny = (lm[i].y - bbox.y) / bbox.h;
    const nz = lm[i].z / bbox.w;
    out[i * 3 + 0] = nx;
    out[i * 3 + 1] = ny;
    out[i * 3 + 2] = nz;
  }
  return out;
}

// ==================================================
// normalize
// ==================================================
function normalize(vec: Float32Array, mean: number[], scale: number[]) {
  const out = new Float32Array(1434);
  for (let i = 0; i < 1434; i++) {
    out[i] = (vec[i] - mean[i]) / scale[i];
  }
  return out;
}

// ==================================================
// ONNX ê°ì • ì¶”ë¡  (ìµœì¢… ì•ˆì • ë²„ì „)
// ==================================================
async function runEmotion(
  session: ort.InferenceSession,
  vec1434: Float32Array,
  scaler: { mean: number[]; scale: number[] }
) {
  // normalize
  const norm = normalize(vec1434, scaler.mean, scaler.scale);

  // tensor
  const inputTensor = new ort.Tensor("float32", norm, [1, 1434]);

  // ì •í™•í•œ input/output ì´ë¦„
  const inputName = session.inputNames[0]; // "input"
  const outputName = session.outputNames[0]; // "keras_tensor_44"

  const output = await session.run({ [inputName]: inputTensor });
  const raw = Array.from(output[outputName].data as Float32Array);

  const probs = softmax(raw);
  const idx = probs.indexOf(Math.max(...probs));

  return {
    emotion: EMOTIONS[idx],
    level: Math.floor(probs[idx] * 3) + 1,
  };
}

// ==================================================
// MAIN COMPONENT
// ==================================================
interface FaceMeshProcessorProps {
  imageSrc: string;
  onRetake: () => void;
  onAnalysisComplete?: (
    emotion: string,
    level: number,
    processedImage: string
  ) => void;
  onSaveRequest?: () => void;
  isLoggedIn: boolean;
  isSaving?: boolean;
}

export default function FaceMeshProcessor({
  imageSrc,
  onRetake,
  onAnalysisComplete,
  onSaveRequest,
  isLoggedIn,
  isSaving = false,
}: FaceMeshProcessorProps) {
  // ìƒíƒœ ê´€ë¦¬
  const [scaler, setScaler] = useState<{
    mean: number[];
    scale: number[];
  } | null>(null);

  const [detectionFailed, setDetectionFailed] = useState(false);
  const [isDrawingComplete, setIsDrawingComplete] = useState(false);

  // ğŸ” [ë””ë²„ê¹…ìš©] ë¡œê·¸ ìƒíƒœ ì¶”ê°€
  const [debugLog, setDebugLog] = useState<string[]>([]);

  // ğŸ” [ë””ë²„ê¹…ìš©] ë¡œê·¸ ì¶”ê°€ í•¨ìˆ˜
  const addLog = (msg: string) => {
    console.log(msg); // ì½˜ì†”ì—ë„ ì°ê³ 
    setDebugLog((prev) => [
      ...prev,
      `${new Date().toLocaleTimeString()} : ${msg}`,
    ]); // í™”ë©´ì—ë„ ì°ìŒ
  };

  const isRunningRef = useRef(false);

  const canvasRef = useRef<HTMLCanvasElement>(null);

  // ê³µìœ  í›… ì‚¬ìš©
  const { downloadImage } = useShareAndDownload();

  // 1. ì´ˆê¸° ë¡œë”©: ì˜¤ì§ 'Scaler' ë°ì´í„°ë§Œ ë¡œë“œ (ê°€ë²¼ì›€)
  useEffect(() => {
    async function loadScaler() {
      try {
        const isIOS = /iPhone|iPad|iPod/i.test(navigator.userAgent);
        addLog(`ğŸ“± ê¸°ê¸°: ${isIOS ? "iOS" : "PC/Android"}`);
        addLog("âš¡ ì „ëµ: ìˆœì°¨ ì‹¤í–‰ (ë©”ëª¨ë¦¬ ì ˆì•½)");

        const res = await fetch("/models/mlp_v2_scaler.json");
        const raw = await res.json();
        setScaler({
          mean: raw.mean_ || raw.mean,
          scale: raw.scale_ || raw.scale,
        });
        addLog("âœ… ì„¤ì • ë°ì´í„° ë¡œë“œ ì™„ë£Œ");
      } catch (e) {
        addLog(`ğŸš¨ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: ${e}`);
      }
    }
    loadScaler();
  }, []);

  // 2. ì´ë¯¸ì§€ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ (ì—¬ê¸°ì— ëª¨ë“  ë¡œì§ ì§‘ì¤‘)
  useEffect(() => {
    if (!scaler || !imageSrc || !canvasRef.current) return;

    const canvas = canvasRef.current;
    const ctx = canvas.getContext("2d", { willReadFrequently: true });
    if (!ctx) return;

    setIsDrawingComplete(false);
    setDetectionFailed(false);

    const userImage = new Image();
    userImage.src = imageSrc;
    userImage.crossOrigin = "anonymous";

    userImage.onload = async () => {
      // ìº”ë²„ìŠ¤ ì´ˆê¸°í™” ë° ê·¸ë¦¬ê¸°
      canvas.width = 1440;
      canvas.height = 1920;
      const canvasAspectRatio = canvas.width / canvas.height;
      const imageAspectRatio = userImage.naturalWidth / userImage.naturalHeight;
      let sx = 0,
        sy = 0,
        sWidth = userImage.naturalWidth,
        sHeight = userImage.naturalHeight;

      if (imageAspectRatio > canvasAspectRatio) {
        sWidth = userImage.naturalHeight * canvasAspectRatio;
        sx = (userImage.naturalWidth - sWidth) / 2;
      } else {
        sHeight = userImage.naturalWidth / canvasAspectRatio;
        sy = (userImage.naturalHeight - sHeight) / 2;
      }
      ctx.drawImage(
        userImage,
        sx,
        sy,
        sWidth,
        sHeight,
        0,
        0,
        canvas.width,
        canvas.height
      );

      if (isRunningRef.current) return;
      isRunningRef.current = true;

      // ğŸ›‘ í•µì‹¬ ë¡œì§: ë‹¨ê³„ë³„ ë¡œë”© -> ì‹¤í–‰ -> ì‚­ì œ
      setTimeout(async () => {
        let landmarker: FaceLandmarker | null = null;
        let session: ort.InferenceSession | null = null;

        try {
          const isIOS = /iPhone|iPad|iPod/i.test(navigator.userAgent);

          // -------------------------------------------------------
          // [STEP 1] FaceMesh ë¡œë“œ & ì‹¤í–‰ & ì‚­ì œ
          // -------------------------------------------------------
          addLog("1ï¸âƒ£ FaceMesh ëª¨ë¸ ë¡œë”© ì¤‘...");
          const resolver = await FilesetResolver.forVisionTasks(
            "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
          );
          landmarker = await FaceLandmarker.createFromOptions(resolver, {
            baseOptions: {
              modelAssetPath: "/models/face_landmarker.task",
              delegate: "CPU", // iOS ì•ˆì •ì„±
            },
            runningMode: "IMAGE",
          });

          // ì´ë¯¸ì§€ ì¶•ì†Œ (256px)
          const ANALYSIS_WIDTH = 256;
          const analysisScale = ANALYSIS_WIDTH / userImage.naturalWidth;
          const analysisHeight = userImage.naturalHeight * analysisScale;
          const smallCanvas = document.createElement("canvas");
          smallCanvas.width = ANALYSIS_WIDTH;
          smallCanvas.height = analysisHeight;
          const smallCtx = smallCanvas.getContext("2d", {
            willReadFrequently: true,
          });
          smallCtx?.drawImage(userImage, 0, 0, ANALYSIS_WIDTH, analysisHeight);

          addLog("ğŸ“¸ ì–¼êµ´ ê°ì§€ ì‹¤í–‰...");
          const result = landmarker.detect(smallCanvas);

          // ğŸ—‘ï¸ [ì¤‘ìš”] FaceMesh ë©”ëª¨ë¦¬ ì¦‰ì‹œ í•´ì œ!
          landmarker.close();
          landmarker = null;
          addLog("ğŸ—‘ï¸ FaceMesh ë©”ëª¨ë¦¬ í•´ì œ ì™„ë£Œ");

          if (!result.faceLandmarks.length) {
            addLog("âŒ ì–¼êµ´ ì—†ìŒ");
            setDetectionFailed(true);
            setIsDrawingComplete(true);
            return;
          }
          const lm = result.faceLandmarks[0];

          // -------------------------------------------------------
          // [STEP 2] ì ì‹œ ëŒ€ê¸° (GC ì‹œê°„ ë²Œê¸°)
          // -------------------------------------------------------
          // addLog("â˜•ï¸ ë©”ëª¨ë¦¬ ì •ë¦¬ ëŒ€ê¸° (1ì´ˆ)...");
          // await new Promise(r => setTimeout(r, 1000));

          // -------------------------------------------------------
          // [STEP 3] ONNX ë¡œë“œ & ì‹¤í–‰ & ì‚­ì œ
          // -------------------------------------------------------
          addLog("2ï¸âƒ£ ê°ì • ëª¨ë¸(ONNX) ë¡œë”© ì¤‘...");

          // ëª¨ë¸ ê²½ë¡œ (ê²½ëŸ‰í™” ëª¨ë¸ ì‚¬ìš©)
          // const modelPath = isIOS ? "/models/mlp_v2_small.onnx" : "/models/mlp_v2.onnx";

          session = await ort.InferenceSession.create("/models/mlp_v2.onnx", {
            executionProviders: isIOS ? ["wasm"] : ["webgpu", "webgl", "wasm"],
          });

          addLog("ğŸ§  ê°ì • ë¶„ì„ ì‹¤í–‰...");
          const bbox = computeBBox(lm);
          const vec = landmarksToVec1434_CropNorm(lm, bbox);
          const aiResult = await runEmotion(session, vec, scaler);

          // ğŸ—‘ï¸ [ì¤‘ìš”] ONNX ë©”ëª¨ë¦¬ í•´ì œ (ë³€ìˆ˜ ì´ˆê¸°í™”)
          session = null;
          addLog("ğŸ—‘ï¸ ONNX ë©”ëª¨ë¦¬ í•´ì œ ì™„ë£Œ");

          addLog(`ğŸ‰ ê²°ê³¼: ${aiResult.emotion}`);

          // -------------------------------------------------------
          // [STEP 4] ê²°ê³¼ ê·¸ë¦¬ê¸°
          // -------------------------------------------------------
          const iconToDraw = new Image();
          iconToDraw.src = `/images/emotions/${aiResult.emotion}_${aiResult.level}.png`;
          await new Promise((resolve) => (iconToDraw.onload = resolve));

          const scaledLandmarks = lm.map((landmark) => {
            const originalX = landmark.x * userImage.naturalWidth;
            const originalY = landmark.y * userImage.naturalHeight;
            const canvasX = ((originalX - sx) / sWidth) * canvas.width;
            const canvasY = ((originalY - sy) / sHeight) * canvas.height;
            return {
              x: canvasX / canvas.width,
              y: canvasY / canvas.height,
              z: landmark.z,
            };
          });

          ICON_PLACEMENTS.forEach((placement) => {
            const landmark = scaledLandmarks[placement.landmarkIndex];
            const x = landmark.x * canvas.width + placement.offsetX;
            const y = landmark.y * canvas.height + placement.offsetY;
            ctx.drawImage(iconToDraw, x, y, placement.width, placement.height);
          });

          setIsDrawingComplete(true);

          // ìµœì¢… ê²°ê³¼ ìƒì„±
          const finalImage = canvas.toDataURL("image/jpeg", 0.7);
          if (onAnalysisComplete) {
            onAnalysisComplete(aiResult.emotion, aiResult.level, finalImage);
          }
        } catch (error) {
          console.error(error);
          addLog(`ğŸš¨ ì—ëŸ¬: ${error}`);
        } finally {
          // ì•ˆì „ì¥ì¹˜: í˜¹ì‹œ ì—ëŸ¬ë‚˜ì„œ ì•ˆ ë‹«í˜”ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„
          if (landmarker) (landmarker as FaceLandmarker).close();
          session = null;
          isRunningRef.current = false;
        }
      }, 100); // UI ë Œë”ë§ í›„ ì‹œì‘
    };
  }, [scaler, imageSrc]); // ì˜ì¡´ì„± ë°°ì—´ì—ì„œ ëª¨ë¸ ì œê±°ë¨

  // ê³µìœ í•˜ê¸° í•¸ë“¤ëŸ¬
  const handleShare = async () => {
    if (!canvasRef.current || !isDrawingComplete) return;
    const dateStr = getTodayDateString();
    try {
      const canvas = canvasRef.current;
      const blob = await new Promise<Blob | null>((resolve) =>
        canvas.toBlob(resolve, "image/png")
      );
      if (!blob) return alert("ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨");

      const filename = `today-haru_${dateStr}.png`;
      const file = new File([blob], filename, {
        type: "image/png",
      });

      if (navigator.canShare && navigator.canShare({ files: [file] })) {
        await navigator.share({
          files: [file],
          title: "ì˜¤ëŠ˜:í•˜ë£¨ ê°ì • ë¶„ì„",
          text: "ë‚´ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”!",
        });
      } else {
        alert("ì´ ë¸Œë¼ìš°ì €ëŠ” ê³µìœ ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      }
    } catch (error) {
      console.log("ê³µìœ  ì·¨ì†Œë¨");
    }
  };

  const handleDownload = () => {
    if (!canvasRef.current) return;
    const dateStr = getTodayDateString();
    const url = canvasRef.current.toDataURL("image/png");
    downloadImage(url, `today-haru_${dateStr}.png`);
  };

  return (
    <div className="w-full h-full">
      <div className="w-full p-4 bg-app-bg-secondary">
        <Card className="mobile-container bg-gray-200 relative">
          {!scaler && (
            <div className="absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 ">
              <LoadingSpinner />
            </div>
          )}

          <div className="aspect-3/4">
            <canvas ref={canvasRef} className="w-full h-full" />
          </div>

          {detectionFailed && (
            <div className="text-center p-4 my-2 bg-red-100 border border-red-400 text-red-700 rounded-lg">
              <p className="font-bold">ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>
              <p className="text-sm">ë‹¤ë¥¸ ì‚¬ì§„ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.</p>
            </div>
          )}
        </Card>

        <div className="flex items-center justify-between mt-6 gap-3 w-full max-w-md mx-auto">
          <button
            onClick={onRetake}
            disabled={isSaving}
            className="flex-1 py-4 bg-[#F5EFE6] text-[#56412C] font-semibold rounded-2xl shadow-md hover:bg-[#EADCC7]"
          >
            ë‹¤ì‹œ ì´¬ì˜
          </button>

          {onSaveRequest && !detectionFailed && (
            <button
              onClick={onSaveRequest}
              disabled={!isDrawingComplete || isSaving}
              className="flex-1 py-4 bg-app-bg-tertiary text-white font-bold rounded-2xl shadow-md hover:bg-[#3E2E1E]"
            >
              {isSaving
                ? "ì €ì¥ ì¤‘..."
                : isLoggedIn
                ? "ì €ì¥í•˜ê¸°"
                : "ë¡œê·¸ì¸/ì €ì¥"}
            </button>
          )}
        </div>
      </div>

      {!detectionFailed && (
        <div className="w-full px-4 py-6 mt-4 bg-app-bg-secondary">
          <div className="flex flex-col items-center space-y-4 w-full">
            <button
              onClick={handleShare}
              className="w-full max-w-sm py-3.5 bg-white border-2 border-app-bg-secondary text-app-bg-secondary font-bold rounded-2xl shadow-sm hover:bg-[#FAF7F2]"
            >
              ê³µìœ í•˜ê¸°
            </button>

            <button
              onClick={handleDownload}
              className="w-full max-w-sm py-3.5 bg-[#F5EFE6] font-bold text-[#56412C] rounded-2xl shadow-sm hover:bg-[#EADCC7]"
            >
              ì´ë¯¸ì§€ë¡œ ë‹¤ìš´ë¡œë“œ
            </button>
          </div>
        </div>
      )}
      {/* ğŸ” [ë””ë²„ê¹…ìš© ë¡œê·¸ UI] 
        - í…ŒìŠ¤íŠ¸ê°€ ëë‚˜ë©´ ì´ ì•„ë˜ div ë¶€ë¶„ë§Œ ì§€ìš°ì‹œë©´ ë©ë‹ˆë‹¤!
      */}
      <div className="fixed bottom-0 left-0 w-full bg-black/90 text-green-400 text-xs overflow-y-auto z-[9999] p-3 pointer-events-none font-mono opacity-80">
        <div className="font-bold text-white mb-2 border-b border-gray-600 pb-1">
          ğŸ› ï¸ ì‹¤ì‹œê°„ ì²˜ë¦¬ ë¡œê·¸
        </div>
        {debugLog.length === 0 && (
          <div className="text-gray-500">ëŒ€ê¸° ì¤‘...</div>
        )}
        {debugLog.map((log, i) => (
          <div key={i} className="mb-1 border-b border-gray-800 pb-1">
            {log}
          </div>
        ))}
      </div>
    </div>
  );
}
